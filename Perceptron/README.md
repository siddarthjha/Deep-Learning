# Implementaion of a multi layer perceptron using Tensorflow

We will be building 

* 784(Input)

* 512(Hidden layer 1)

* 256(Hidden layer 2)

* 10(Output) neural network model.

This is a **Deep Neural network**
1. Inputs/Input Layer.
2. Weights & Bias.
3. Net Sum.
4. Activation Function (Sigmoid, tanh, RELu)

This works in the same way as a neural network works:
1. The inputs are multiplied with the weights and all the individuals are added.
2. The net sum is applied to activation function for the output.

**Why Weight?**

Because it shows the strength of the particular node
